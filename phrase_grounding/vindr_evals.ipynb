{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/bglocker/ugproj2324/nns20/cxr-agent/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pip_source = \"hi-ml-multimodal\"\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import random \n",
    "\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/vol/biomedic3/bglocker/ugproj2324/nns20/.hi-ml-cache\"\n",
    "\n",
    "from health_multimodal.common.visualization import plot_phrase_grounding_similarity_map\n",
    "from health_multimodal.text import get_bert_inference\n",
    "from health_multimodal.text.utils import BertEncoderType\n",
    "from health_multimodal.image import get_image_inference\n",
    "from health_multimodal.image.utils import ImageModelType\n",
    "from health_multimodal.vlp import ImageTextInferenceEngine\n",
    "\n",
    "from agent_utils import select_best_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'CXRBertTokenizer'.\n",
      "You are using a model of type bert to instantiate a model of type cxr-bert. This is not supported for all configurations of models and can yield errors.\n",
      "/vol/biomedic3/bglocker/ugproj2324/nns20/cxr-agent/.venv/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at microsoft/BiomedVLP-BioViL-T were not used when initializing CXRBertModel: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CXRBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CXRBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://cdn-lfs.huggingface.co/repos/63/2f/632fbb459426d5c3e8e64aa8be737ccf0c8ba541980f23a79ecf1ab6e87df8b4/b2399d73dc2a68b9f3a1950e864ae0ecd24093fb07aa459d7e65807ebdc0fb77?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27biovil_t_image_model_proj_size_128.pt%3B+filename%3D%22biovil_t_image_model_proj_size_128.pt%22%3B&Expires=1715695775&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNTY5NTc3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82My8yZi82MzJmYmI0NTk0MjZkNWMzZThlNjRhYThiZTczN2NjZjBjOGJhNTQxOTgwZjIzYTc5ZWNmMWFiNmU4N2RmOGI0L2IyMzk5ZDczZGMyYTY4YjlmM2ExOTUwZTg2NGFlMGVjZDI0MDkzZmIwN2FhNDU5ZDdlNjU4MDdlYmRjMGZiNzc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=a9gxkLcB9AO6UyUQ8xDNoeb1MR2fwG%7EMLzlJux1yxGodr5vUteMpYOk91ZztTgoq0f87zl4WWJaywq4u-jk-AIlz7VYOSzJjvYze1RGPHNFa8ckXMi4f2xd%7EaIHLnfK5vIVu%7E74FLve7Cdw1rxSJrHllZ3%7ERZmrIGJrk7XZN7P8g2mabzM3UF3zsYGxVyh4OZM1sHO%7EKptJdnscVLdBl3hghKix-Wad7-esUy-AxSUAgqBNURZCqWKWEW%7E6qojREjnY0fHUp4CDtFFub0MBlKcg5HQXocZ0XPsa3QKW8j-sNWDerfA3yOQNLtE2WE32aQnp-HeEKLSLbT%7EIHC75row__&Key-Pair-Id=KVTP0A1DKRTAX to /tmp/biovil_t_image_model_proj_size_128.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109745561/109745561 [00:00<00:00, 113390221.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2080 Ti, Free memory: 11002 MB\n",
      "GPU 1: NVIDIA GeForce RTX 2080 Ti, Free memory: 10977 MB\n",
      "Selecting GPU 0 with 11002 MB free memory, Device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "text_inference = get_bert_inference(BertEncoderType.BIOVIL_T_BERT)\n",
    "image_inference = get_image_inference(ImageModelType.BIOVIL_T)\n",
    "image_text_inference = ImageTextInferenceEngine(\n",
    "    image_inference_engine=image_inference,\n",
    "    text_inference_engine=text_inference,\n",
    ")\n",
    "device = select_best_gpu()\n",
    "image_text_inference.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2\n",
    "top_n = 25\n",
    "\n",
    "def get_top_values(similarity_map,threshold, top_n=top_n):\n",
    "    top_values = []\n",
    "    for i in range(similarity_map.shape[0]):\n",
    "        for j in range(similarity_map.shape[1]):\n",
    "            if similarity_map[i, j] > threshold:\n",
    "                top_values.append((i, j, similarity_map[i, j]))\n",
    "\n",
    "    top_values = sorted(top_values, key = lambda x: x[2], reverse = True)\n",
    "    return top_values[:top_n]\n",
    "\n",
    "def calculate_mean(similarity_map_top_values):\n",
    "    if len(similarity_map_top_values) == 0:\n",
    "        return 0\n",
    "    return sum([x[2] for x in similarity_map_top_values]) / len(similarity_map_top_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection_threshold=0.25\n",
      "total=88\n",
      "total_left=69\n",
      "total_right=32\n",
      "Exact Match Accuracy: 0.3181818181818182\n",
      "Left Accuracy: 0.6136363636363636\n",
      "Right Accuracy: 0.4431818181818182\n",
      "\n",
      "\n",
      "detection_threshold=0.35\n",
      "total=64\n",
      "total_left=69\n",
      "total_right=32\n",
      "Exact Match Accuracy: 0.40625\n",
      "Left Accuracy: 0.515625\n",
      "Right Accuracy: 0.453125\n",
      "\n",
      "\n",
      "detection_threshold=0.45\n",
      "total=36\n",
      "total_left=69\n",
      "total_right=32\n",
      "Exact Match Accuracy: 0.6111111111111112\n",
      "Left Accuracy: 0.3888888888888889\n",
      "Right Accuracy: 0.6388888888888888\n",
      "\n",
      "\n",
      "detection_threshold=0.55\n",
      "total=21\n",
      "total_left=69\n",
      "total_right=32\n",
      "Exact Match Accuracy: 0.7142857142857143\n",
      "Left Accuracy: 0.2857142857142857\n",
      "Right Accuracy: 0.7142857142857143\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vindr_pathology_left_or_right_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/datasets/VinDr-CXR/image_text_reasoning_datasets/test_pathology_left_or_right\")\n",
    "vindr_png_path = Path('/vol/biodata/data/chest_xray/VinDr-CXR/1.0.0_png_512/raw/test')\n",
    "\n",
    "detection_thresholds = [0.25,0.35,0.45,0.55]\n",
    "\n",
    "with open(vindr_pathology_left_or_right_path) as f:\n",
    "\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for detection_threshold in detection_thresholds:\n",
    "\n",
    "        print(f\"{detection_threshold=}\")\n",
    "        exact_match = 0\n",
    "        left_correct = 0\n",
    "        right_correct = 0\n",
    "\n",
    "        total = 0\n",
    "        total_left = 0\n",
    "        total_right = 0\n",
    "\n",
    "        for index, line in enumerate(lines):\n",
    "            image_id, text_prompt, ground_truth_side = line.strip().split(\",\")\n",
    "            image_path = vindr_png_path / f\"{image_id}.png\"\n",
    "\n",
    "            left_similarity_map = image_text_inference.get_similarity_map_from_raw_data(\n",
    "                image_path=image_path,\n",
    "                query_text=f\"left {text_prompt}\",\n",
    "                interpolation=\"bilinear\",\n",
    "            )\n",
    "\n",
    "            right_similarity_map = image_text_inference.get_similarity_map_from_raw_data(\n",
    "                image_path=image_path,\n",
    "                query_text=f\"right {text_prompt}\",\n",
    "                interpolation=\"bilinear\",\n",
    "            )\n",
    "\n",
    "            left_mean_activation = calculate_mean(get_top_values(left_similarity_map, detection_threshold))\n",
    "            right_mean_activation = calculate_mean(get_top_values(right_similarity_map, detection_threshold))\n",
    "            \n",
    "            locations = []\n",
    "            if left_mean_activation >= detection_threshold:\n",
    "                locations.append(\"left\")\n",
    "            \n",
    "            if right_mean_activation >= detection_threshold:\n",
    "                locations.append(\"right\")\n",
    "\n",
    "            predictions = \" and \".join(locations)\n",
    "\n",
    "            # print(f\"{left_mean_activation=}\")\n",
    "            # print(f\"{right_mean_activation=}\")\n",
    "            # print(f\"Ground Truth Side: {ground_truth_side}\")\n",
    "            # print(f\"Predictions: {predictions}\")\n",
    "\n",
    "            if left_mean_activation + right_mean_activation > 0:\n",
    "                total += 1\n",
    "        \n",
    "            if \"left\" in ground_truth_side:#  and not \"right\" in ground_truth_side:\n",
    "                total_left += 1\n",
    "            elif \"right\" in ground_truth_side:# and not \"left\" in ground_truth_side:\n",
    "                total_right += 1\n",
    "\n",
    "            if ground_truth_side == predictions:\n",
    "                exact_match += 1\n",
    "\n",
    "            if \"left\" in ground_truth_side and \"left\" in locations:\n",
    "                left_correct += 1\n",
    "\n",
    "            if \"right\" in ground_truth_side and \"right\" in locations:\n",
    "                right_correct += 1\n",
    "\n",
    "            if index == 100:\n",
    "                break\n",
    "\n",
    "        \n",
    "        print(f\"{total=}\")\n",
    "        print(f\"{total_left=}\")\n",
    "        print(f\"{total_right=}\")\n",
    "\n",
    "        print(f\"Exact Match Accuracy: {exact_match/total}\")\n",
    "        print(f\"Left Accuracy: {left_correct/total}\")\n",
    "        print(f\"Right Accuracy: {right_correct/total}\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
