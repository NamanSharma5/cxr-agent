{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import TypeAlias, Union\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "# Add the base_agent directory to sys.path\n",
    "base_agent_dir = \"/vol/biomedic3/bglocker/ugproj2324/nns20/cxr-agent/base_agent\"\n",
    "sys.path.insert(0, str(base_agent_dir))\n",
    "\n",
    "from pathology_sets import Pathologies\n",
    "from pathology_detector import CheXagentVisionTransformerPathologyDetector\n",
    "from phrase_grounder import BioVilTPhraseGrounder\n",
    "from generation_engine import GenerationEngine, Llama3Generation, CheXagentLanguageModelGeneration, GeminiFlashGeneration\n",
    "\n",
    "\n",
    "pathology_dict_type: TypeAlias = dict[set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = None #\"cuda:1\"  \n",
    "PATHOLOGY_DETECTION_THRESHOLD = 0.4\n",
    "PHRASE_GROUNDING_THRESHOLD = 0.2\n",
    "\n",
    "USER_PROMPT = \"Just list the findings on the chest x-ray, nothing else. If there are no findings, just say that.\"\n",
    "IGNORE_PATHOLOGIES = {} #{\"Support Devices\"}\n",
    "DO_NOT_LOCALISE = {\"Cardiomegaly\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and save outputs of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VinDr paths\n",
    "vinDr_test_ground_truth_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/datasets/VinDr-CXR/test_set_three_splits/VinDr_test_test_split_with_one_hot_labels.csv\")\n",
    "\n",
    "vindr_pathologies = [\"Aortic enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\",\n",
    "            \"Clavicle fracture\", \"Consolidation\", \"Emphysema\", \"Enlarged PA\",\n",
    "            \"ILD\", \"Infiltration\", \"Lung Opacity\", \"Lung cavity\", \"Lung cyst\",\n",
    "            \"Mediastinal shift\",\"Nodule/Mass\", \"Pleural effusion\", \"Pleural thickening\",\n",
    "            \"Pneumothorax\", \"Pulmonary fibrosis\",\"Rib fracture\", \"Other lesion\",\n",
    "            \"No finding\"] \n",
    "\n",
    "# CheXpert paths\n",
    "cheXpert_test_ground_truth_path = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/datasets/CheXpert/test.csv\")\n",
    "cheXpert_test_path = Path(\"/vol/biodata/data/chest_xray/CheXpert-v1.0-small/CheXpert-v1.0-small/test\")\n",
    "\n",
    "# CheXpert pathologies\n",
    "cheXpert_pathologies = ['No Finding','Enlarged Cardiomediastinum','Cardiomegaly','Lung Opacity',\n",
    "        'Lung Lesion','Edema','Consolidation','Pneumonia','Atelectasis','Pneumothorax',\n",
    "        'Pleural Effusion','Pleural Other','Fracture','Support Devices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4090, Free memory: 24177 MB\n",
      "GPU 1: NVIDIA GeForce RTX 4090, Free memory: 24203 MB\n",
      "Selecting GPU 1 with 24203 MB free memory, Device = cuda:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af425cf5c7914e14b4a673e07fbbb577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheXagent Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'CXRBertTokenizer'.\n",
      "You are using a model of type bert to instantiate a model of type cxr-bert. This is not supported for all configurations of models and can yield errors.\n",
      "/vol/biomedic3/bglocker/ugproj2324/nns20/cxr-agent/.venv/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at microsoft/BiomedVLP-BioViL-T were not used when initializing CXRBertModel: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CXRBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CXRBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /tmp/biovil_t_image_model_proj_size_128.pt\n",
      "GPU 0: NVIDIA GeForce RTX 4090, Free memory: 23788 MB\n",
      "GPU 1: NVIDIA GeForce RTX 4090, Free memory: 6991 MB\n",
      "Selecting GPU 0 with 23788 MB free memory, Device = cuda:0\n",
      "GPU 0: NVIDIA GeForce RTX 4090, Free memory: 23216 MB\n",
      "GPU 1: NVIDIA GeForce RTX 4090, Free memory: 6991 MB\n",
      "Selecting GPU 0 with 23216 MB free memory, Device = cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053d4514517344268bd1f76f5a1115b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "pathology_detector = CheXagentVisionTransformerPathologyDetector(pathologies=Pathologies.CHEXPERT, device=DEVICE)\n",
    "phrase_grounder = BioVilTPhraseGrounder(detection_threshold=PHRASE_GROUNDING_THRESHOLD, device = DEVICE)\n",
    "l3 = Llama3Generation(device = DEVICE)\n",
    "cheXagent_lm = CheXagentLanguageModelGeneration(pathology_detector.processor, pathology_detector.model, pathology_detector.generation_config, pathology_detector.device, pathology_detector.dtype)\n",
    "gemini = GeminiFlashGeneration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/bglocker/ugproj2324/nns20/cxr-agent/.hf_cache/modules/transformers_modules/4934e91451945c8218c267aae9c34929a7677829/processing_chexagent.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  [torch.tensor(pixel_values) for pixel_values in encoding_image_processor[\"pixel_values\"]]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'patient64741/study1/view1_frontal.jpg': {'chexagent': 'The endotracheal tube is in a standard position. The Swan-Ganz catheter terminates in the right pulmonary artery. The left internal jugular central venous catheter terminates in the mid SVC. The nasogastric tube terminates in the stomach. The cardiomediastinal silhouette is stable. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no', 'gemini_agent': 'Support devices, probable lung opacity, probable pleural effusion \\n', 'llama3_agent': 'cannot exclude Cardiomegaly\\npossible Lung Opacity\\nprobable Pleural Effusion\\nSupport Devices', 'chexagent_agent': 'There are no findings on the chest x-ray.'}})\n"
     ]
    }
   ],
   "source": [
    "model_outputs = defaultdict(dict)\n",
    "with open(cheXpert_test_ground_truth_path) as chexpert_test_file:\n",
    "    for index, line in enumerate(chexpert_test_file):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        image_id = line.strip().split(\",\")[0]\n",
    "        image_path = cheXpert_test_path / image_id\n",
    "        pathology_confidences, localised_pathologies, chexagent_e2e = GenerationEngine.detect_and_localise_pathologies(\n",
    "            image_path=image_path,\n",
    "            pathology_detector=pathology_detector,\n",
    "            phrase_grounder=phrase_grounder,\n",
    "            pathology_detection_threshold = PATHOLOGY_DETECTION_THRESHOLD,\n",
    "            ignore_pathologies=IGNORE_PATHOLOGIES,\n",
    "            do_not_localise=DO_NOT_LOCALISE,\n",
    "            prompt_for_chexagent_lm_output= USER_PROMPT,\n",
    "        )\n",
    "        \n",
    "        model_outputs[image_id]['chexagent'] = chexagent_e2e\n",
    "\n",
    "        gemini_system_prompt, gemini_image_context_prompt = gemini.generate_prompts(pathology_confidences, localised_pathologies)\n",
    "        model_outputs[image_id]['gemini_agent'] = gemini.generate_model_output(gemini_system_prompt, gemini_image_context_prompt, user_prompt=USER_PROMPT)\n",
    "\n",
    "        def run_chexagent_lm(pathology_confidences, localised_pathologies):\n",
    "            system_prompt, image_context_prompt = GenerationEngine.generate_prompts(pathology_confidences, localised_pathologies)\n",
    "            return cheXagent_lm.generate_model_output(system_prompt, image_context_prompt, user_prompt=USER_PROMPT)\n",
    "\n",
    "        def run_llama3_agent(pathology_confidences, localised_pathologies):\n",
    "            system_prompt, image_context_prompt = l3.generate_prompts(pathology_confidences, localised_pathologies)\n",
    "            return l3.generate_model_output(system_prompt, image_context_prompt, user_prompt=USER_PROMPT)\n",
    "        \n",
    "        def run_gemini_agent(pathology_confidences, localised_pathologies):\n",
    "            system_prompt, image_context_prompt = gemini.generate_prompts(pathology_confidences, localised_pathologies)\n",
    "            return gemini.generate_model_output(system_prompt, image_context_prompt, user_prompt=USER_PROMPT)\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:       \n",
    "            # Run cheXagent_lm and l3 in parallel\n",
    "            future_chexagent_lm = executor.submit(run_chexagent_lm, pathology_confidences, localised_pathologies)\n",
    "            future_llama3_agent = executor.submit(run_llama3_agent, pathology_confidences, localised_pathologies)\n",
    "\n",
    "            for future in as_completed([future_chexagent_lm, future_llama3_agent]):\n",
    "                if future == future_chexagent_lm:\n",
    "                    model_outputs[image_id]['chexagent_agent'] = future.result()\n",
    "                else:\n",
    "                    model_outputs[image_id]['llama3_agent'] = future.result()\n",
    "\n",
    "        print(model_outputs)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['patient64741/study1/view1_frontal.jpg'])\n",
      "patient64741/study1/view1_frontal.jpg {'chexagent': 'The endotracheal tube is in a standard position. The Swan-Ganz catheter terminates in the right pulmonary artery. The left internal jugular central venous catheter terminates in the mid SVC. The nasogastric tube terminates in the stomach. The cardiomediastinal silhouette is stable. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no pneumothorax. There is no', 'gemini_agent': 'Support devices, probable lung opacity, probable pleural effusion \\n', 'llama3_agent': 'cannot exclude Cardiomegaly\\npossible Lung Opacity\\nprobable Pleural Effusion\\nSupport Devices', 'chexagent_agent': 'There are no findings on the chest x-ray.'}\n",
      "<class 'str'> <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "cheXpert_output_folder = Path(\"/vol/biomedic3/bglocker/ugproj2324/nns20/cxr-agent/base_agent/evaluation/cheXpert\")\n",
    "print(model_outputs.keys())\n",
    "\n",
    "def dump_outputs_to_files(model_outputs: dict, output_folder: Path):\n",
    "    for image_id, model_dict in model_outputs.items():\n",
    "        print(image_id, model_dict)\n",
    "        print(type(image_id), type(model_dict))\n",
    "        \n",
    "        for model_name, model_output in model_dict.items():\n",
    "            # replace any new lines in the model output with full stops\n",
    "            model_output = model_output.replace(\"\\n\", \".\")\n",
    "            with open(output_folder / f\"{model_name}.txt\", \"a\") as output_file:\n",
    "                output_file.write(f\"{image_id},{model_output}\")\n",
    "    \n",
    "dump_outputs_to_files(model_outputs, cheXpert_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pathologies_in_sentences(text, pathologies):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    detected_pathologies = set()\n",
    "\n",
    "    negation_keywords = r\"\\bno\\b|\\bnot\\b|\\bwithout\\b|\\babsent\\b\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        lower_sentence = sentence.lower()\n",
    "        pathologies_in_sentence = set()\n",
    "\n",
    "        for pathology in pathologies:\n",
    "            if pathology.lower() in lower_sentence:\n",
    "                pathologies_in_sentence.add(pathology)\n",
    "\n",
    "        # Check for negation in the sentence\n",
    "        negation_match = re.search(negation_keywords, lower_sentence)\n",
    "\n",
    "        # Extract pathologies in 'no xxx or yyy' construction\n",
    "        if negation_match:\n",
    "            ns = negation_match.end()\n",
    "            to_end_sentence = lower_sentence[ns:]\n",
    "            # Look for immediate pathologies after 'no' possibly linked by 'or'/'and'\n",
    "            excluded_pathologies = [p for p in pathologies_in_sentence if p.lower() in to_end_sentence]\n",
    "\n",
    "            # Remove the pathologies that are excluded by negation\n",
    "            pathologies_in_sentence.difference_update(excluded_pathologies)\n",
    "\n",
    "        detected_pathologies.update(pathologies_in_sentence)\n",
    "\n",
    "    return detected_pathologies    \n",
    "\n",
    "def build_image_id_to_pathology_dict(file_path, pathologies, header = False,pathologies_check = True, sentences = False ) -> pathology_dict_type:\n",
    "    image_ids_to_pathologies = defaultdict(set)\n",
    "    \n",
    "    pathologies = [pathology.lower() for pathology in pathologies]\n",
    "    with open(file_path, 'r') as f:\n",
    "        if header:\n",
    "            header = f.readline() # skip header\n",
    "        for line in f.readlines():\n",
    "\n",
    "            if not sentences:\n",
    "                line = line.strip().split(',')\n",
    "                for pathology in line[1:]:\n",
    "                    if pathologies_check and pathology.lower() in pathologies:\n",
    "                        image_ids_to_pathologies[line[0]].add(pathology.lower().strip())\n",
    "                    else:\n",
    "                        image_ids_to_pathologies[line[0]].add(pathology.lower().strip())\n",
    "            \n",
    "            else:\n",
    "                image_id = line.split(',')[0]\n",
    "                text = (',').join(line.split(',')[1:])\n",
    "                detected_pathologies = find_pathologies_in_sentences(text, pathologies)\n",
    "                if len(detected_pathologies) == 0:\n",
    "                    detected_pathologies.add('no finding')\n",
    "                image_ids_to_pathologies[image_id] = detected_pathologies\n",
    "                \n",
    "    return image_ids_to_pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No Finding'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"No findings...\"\n",
    "find_pathologies_in_sentences(test, cheXpert_pathologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_labels(labels, synonym_mapping):\n",
    "    normalized_labels = set()\n",
    "    for label in labels:\n",
    "        found = False\n",
    "        for synonyms in synonym_mapping:\n",
    "            if label in synonyms:\n",
    "                normalized_labels.add(frozenset(synonyms))  # Adding the frozenset of synonyms\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            normalized_labels.add(label)\n",
    "    return normalized_labels\n",
    "\n",
    "\n",
    "def contains_no_finding(label_set, synonym_mappings):\n",
    "    for synonyms in synonym_mappings:\n",
    "        if \"no finding\" in synonyms:\n",
    "            if frozenset(synonyms) in label_set:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def convert_probabilities_to_labels(file_path: Path,pathologies, threshold = True, threshold_val = 0.5, top_k = False, k = 1) -> pathology_dict_type:\n",
    "    image_ids_to_pathologies = defaultdict(set)\n",
    "    pathologies = [pathology.lower() for pathology in pathologies]\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        # header contains mapping of pathology index to pathology name\n",
    "        header = f.readline()\n",
    "        pathology_names = header.strip().split(',')[1:]\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split(',')\n",
    "            image_id = line[0]\n",
    "            probabilities = np.array([float(prob) for prob in line[1:]])\n",
    "            for i, prob in enumerate(probabilities):\n",
    "                pathology = pathology_names[i].lower()\n",
    "                if pathology not in pathologies:\n",
    "                    continue\n",
    "\n",
    "                if threshold:\n",
    "                    if prob >= threshold_val:\n",
    "                        image_ids_to_pathologies[image_id].add(pathology)\n",
    "                elif top_k:\n",
    "                    if i in np.argsort(probabilities)[-k:]:\n",
    "                        if probabilities[i] >= threshold_val: # threshold_val should be 0.5 when threshold flag is False\n",
    "                            image_ids_to_pathologies[image_id].add(pathology)\n",
    "                else:\n",
    "                    return ValueError(\"Invalid arguments for convert_probabilities_to_labels\")\n",
    "            \n",
    "            if len(image_ids_to_pathologies[image_id]) == 0:\n",
    "                image_ids_to_pathologies[image_id].add(\"no finding\")\n",
    "\n",
    "    return image_ids_to_pathologies\n",
    "\n",
    "\n",
    "def calculate_accuracy_metrics(gt_path: Path, preds: Union[Path, pathology_dict_type], gt_pathologies: set, pred_pathologies = None , synonym_mappings = [], threshold = True, threshold_val = 0.5, k = 1):\n",
    "    \"\"\"\n",
    "    Pre-reqs: assume header of probability files will have the pathology names (i.e. image_id, pathology1, pathology2, ...)\n",
    "    \n",
    "    Args:\n",
    "    gt_path: Path to the ground truth file with probabilities\n",
    "    preds: Path to the predictions file with probabilities or a dictionary of image_id to pathologies\n",
    "    gt_pathologies: Set of pathologies to consider in the ground truth, all others will be ignored\n",
    "    pred_pathologies: Set of pathologies to consider in the predictions, all others will be ignored\n",
    "    synonym_mappings: List of lists of synonyms for each pathology\n",
    "    threshold: Flag to determine whether to apply a threshold to the probabilities\n",
    "    threshold_val: Threshold value to apply to the probabilities\n",
    "    k: Number of top k pathologies to consider (only if threshold is False)\n",
    "    \"\"\"\n",
    "    \n",
    "    ground_truth = convert_probabilities_to_labels(gt_path,pathologies = gt_pathologies)\n",
    "    if pred_pathologies is None:\n",
    "        pred_pathologies = gt_pathologies\n",
    "    \n",
    "    if isinstance(preds, Path):\n",
    "        predictions = convert_probabilities_to_labels(preds, pathologies = pred_pathologies, threshold = threshold, threshold_val = threshold_val, top_k = True, k = k)\n",
    "    else:\n",
    "        predictions = preds # Since CheXagent does not give probability bounds on outputs\n",
    "        \n",
    "    # Normalize each set of pathologies in the ground truth and predictions using the provided synonym mappings\n",
    "    normalized_ground_truth = {image_id: normalize_labels(gt_labels, synonym_mappings) for image_id, gt_labels in ground_truth.items()}\n",
    "    normalized_predictions = {image_id: normalize_labels(pred_labels, synonym_mappings) for image_id, pred_labels in predictions.items()}\n",
    "\n",
    "    exact_matches = 0\n",
    "    exact_no_finding = 0\n",
    "    exact_one_pathology = 0\n",
    "    exact_multiple_pathologies = 0\n",
    "\n",
    "    total_no_finding = 0\n",
    "    total_one_pathology = 0\n",
    "    total_multiple_pathologies = 0\n",
    "\n",
    "    correct_matches = 0\n",
    "    correct_no_finding = 0\n",
    "    correct_pathology = 0\n",
    "\n",
    "    correct_top_k_pathology_match = 0\n",
    "\n",
    "    for image_id, ground_truth_labels in normalized_ground_truth.items():\n",
    "        pred_labels = normalized_predictions.get(image_id, set())\n",
    "\n",
    "        is_no_finding = \"no finding\" in ground_truth_labels or contains_no_finding(ground_truth_labels, synonym_mappings)\n",
    "        if is_no_finding:\n",
    "            total_no_finding += 1\n",
    "        elif len(ground_truth_labels) == 1:\n",
    "            total_one_pathology += 1\n",
    "        else:  # Assuming any non-empty set of labels greater than 1 is 'multiple pathologies'\n",
    "            total_multiple_pathologies += 1\n",
    "        \n",
    "        # Calculate exact matches (Metric 1)\n",
    "        if ground_truth_labels == pred_labels:\n",
    "            exact_matches += 1\n",
    "            # Update metrics for matches (Metric 2)\n",
    "            if \"no finding\" in ground_truth_labels or contains_no_finding(ground_truth_labels, synonym_mappings):\n",
    "                exact_no_finding += 1\n",
    "            elif len(ground_truth_labels) == 1:\n",
    "                exact_one_pathology += 1\n",
    "            else:\n",
    "                exact_multiple_pathologies += 1\n",
    "        \n",
    "        # Calculate individual correct matches (Metric 3)\n",
    "        matched_pathologies = ground_truth_labels.intersection(pred_labels)\n",
    "        correct_matches += len(matched_pathologies)\n",
    "        if len(matched_pathologies) > 0:\n",
    "            correct_top_k_pathology_match += 1\n",
    "        \n",
    "        # Update metrics for matches (Metric 4)\n",
    "        for pathology in matched_pathologies:\n",
    "            if \"no finding\" in ground_truth_labels or contains_no_finding({pathology}, synonym_mappings):\n",
    "                correct_no_finding += 1\n",
    "            else:\n",
    "                correct_pathology += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    n = len(ground_truth)\n",
    "    exact_matches_percentage = exact_matches / n\n",
    "    exact_no_finding_percentage = exact_no_finding / total_no_finding if total_no_finding > 0 else 0\n",
    "    exact_one_pathology_percentage = exact_one_pathology / total_one_pathology if total_one_pathology > 0 else 0\n",
    "    exact_multiple_pathologies_percentage = exact_multiple_pathologies / total_multiple_pathologies if total_multiple_pathologies > 0 else 0\n",
    "    \n",
    "    print(f\"\\n\\nDataset Characteristics:\")\n",
    "    print(f\"No finding proportion: {total_no_finding/n:.2f}\")\n",
    "    print(f\"One pathology proportion: {total_one_pathology/n:.2f}\")\n",
    "    print(f\"Multiple pathologies proportion: {total_multiple_pathologies/n:.2f}\")\n",
    "    \n",
    "    print(f\"\\nExact Matches Characteristics:\")\n",
    "    print(f\"Exact matches: {exact_matches_percentage:.2f}\")\n",
    "    print(f\"Exact no finding: {exact_no_finding_percentage:.2f}\")\n",
    "    print(f\"Exact one pathology: {exact_one_pathology_percentage:.2f}\")\n",
    "    print(f\"Exact multiple pathologies: {exact_multiple_pathologies_percentage:.2f}\")\n",
    "    \n",
    "    total_num_of_pathologies = sum([len(pathologies) for pathologies in ground_truth.values()])\n",
    "    correct_matches_percentage = correct_matches / total_num_of_pathologies\n",
    "    correct_no_finding_percentage = correct_no_finding / total_no_finding if total_no_finding > 0 else 0\n",
    "    correct_pathology_percentage = correct_pathology / (total_num_of_pathologies - total_no_finding) if total_num_of_pathologies - total_no_finding > 0 else 0\n",
    "    \n",
    "    print(f\"\\nIndividual Pathology Characteristics:\")\n",
    "    print(f\"Correct matches: {correct_matches_percentage:.2f}\")\n",
    "    print(f\"Correct no finding: {correct_no_finding_percentage:.2f}\")\n",
    "    print(f\"Correct pathology: {correct_pathology_percentage:.2f}\")\n",
    "\n",
    "    print(f\"\\nTop K Pathology Match Characteristics:\")\n",
    "    print(f\"Top K Pathology Match: {correct_top_k_pathology_match/n:.2f}\")\n",
    "\n",
    "    return exact_matches_percentage, exact_no_finding_percentage, exact_one_pathology_percentage, exact_multiple_pathologies_percentage, correct_matches_percentage, correct_no_finding_percentage, correct_pathology_percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
